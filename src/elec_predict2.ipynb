{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "5d7a7e6d-9a88-40e3-b380-171b0edeb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "3b524c53-ba74-441e-bac1-95538af41efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_csv('/Users/mwilson/Documents/GitHub/surveys/data/temp/demo_data_orig.csv')\n",
    "demo = demo.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "6b9e2014-b34d-49d6-ba77-17767e89d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo['edu'] = demo['deg']/(demo['elem']+demo['ass']+demo['deg'])\n",
    "demo['race'] = demo['white']/(demo['white']+demo['black']+demo['nat']+demo['aapi']+demo['mixed'])\n",
    "demo['malefr'] = demo['male']/(demo['male']+demo['female'])\n",
    "demo['femalefr'] = demo['female']/(demo['male']+demo['female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "f6be7a41-02ab-4b1a-937f-9e1587ebc9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = pd.read_csv('/Users/mwilson/Documents/GitHub/election_forecast/data/temp/vote_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "6f6e39e3-4167-46ef-8b5f-f87b3b5d312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the year format so we can work out which ones to average over\n",
    "\n",
    "demo['years'] = demo['year'].str.split(pat='-')\n",
    "def getyear1(row):\n",
    "    return row['years'][0]\n",
    "def getyear2(row):\n",
    "    if(len(row['years'])>1):\n",
    "        return row['years'][1]\n",
    "    else:\n",
    "        return row['years'][0]\n",
    "demo['year1'] = demo.apply(getyear1, axis=1).astype(int)\n",
    "demo['year2'] = demo.apply(getyear2, axis=1).astype(int)\n",
    "demo['pres_year'] = 4*demo['year2'].floordiv(4)\n",
    "cols_to_drop = ['year','years','year1','year2']\n",
    "demo = demo.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# now drop a lot more, maybe too many\n",
    "\n",
    "cols_to_drop = ['white','black','nat','aapi','mixed','elem','ass','deg','male','female']\n",
    "demo = demo.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# remove Puerto Rico\n",
    "\n",
    "demo = demo[demo['state']<57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "6238b8ff-0415-47f3-afd6-3884e7538c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the data covering a given presidential year - can probably do better\n",
    "# no data for 2004 so remove everything\n",
    "\n",
    "demo = demo[demo['pres_year']!=2004]\n",
    "vote = vote[vote['year']!=2004]\n",
    "#pres_years = [2000,2004,2008,2012,2016,2020]\n",
    "\n",
    "demo = demo.groupby(['pres_year','state','county']).mean().reset_index()\n",
    "\n",
    "# get ready for merging with vote\n",
    "\n",
    "demo['year'] = demo['pres_year']\n",
    "demo['fips'] = 1000*demo['state']+demo['county']\n",
    "demo = demo.drop(['pres_year','state','county'],axis=1)\n",
    "\n",
    "vote['fips'] = vote['fips'].astype(int)\n",
    "vote['demfr'] = vote['DEMOCRAT']/vote['totalvotes']\n",
    "vote['repfr'] = vote['REPUBLICAN']/vote['totalvotes']\n",
    "vote['othfr'] = vote['OTHER']/vote['totalvotes']\n",
    "vote['lagdemfr'] = vote['lagDEM']/(vote['lagDEM']+vote['lagREP']+vote['lagOTH'])\n",
    "vote['lagrepfr'] = vote['lagREP']/(vote['lagDEM']+vote['lagREP']+vote['lagOTH'])\n",
    "vote['lagothfr'] = vote['lagOTH']/(vote['lagDEM']+vote['lagREP']+vote['lagOTH'])\n",
    "vote = vote.drop(['DEMOCRAT','REPUBLICAN','OTHER','totalvotes','lagDEM','lagREP','lagOTH'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "6d97eb55-66b4-46fb-b62e-e510c9737097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(vote,demo, on=['year','fips'])\n",
    "df = df.fillna(0)\n",
    "\n",
    "# now add polling data\n",
    "### add new predictors e.g. swing - not used here\n",
    "\n",
    "def sw(v0,vs0,d,str): \n",
    "    if(str==\"ups\"):\n",
    "        di <- d    \n",
    "    elif(str==\"prop\"):\n",
    "        di <- d*v0/vs0\n",
    "    elif(str==\"pw\"):\n",
    "        if d>0:\n",
    "            di = d*(1-v0)/(1-vs0)\n",
    "        else:\n",
    "            di <- d*v0/vs0\n",
    "    return (di) #  Estimate of district level swing\n",
    "\n",
    "poll = pd.DataFrame({\n",
    "    'year': [2000,2008, 2012, 2016, 2020],\n",
    "    'pollDfracdiff': [0,0.052, -0.033, -0.020, 0.044],\n",
    "    'pollRfracdiff': [0,-0.044, 0.036, -0.045, 0.004]\n",
    "})\n",
    "\n",
    "\n",
    "# seems not to work well, so will ignore for now or at least until we can get more data\n",
    "df = pd.merge(df,poll,on='year')\n",
    "df['pollupspredD'] = df['lagdemfr']+df['pollDfracdiff'] # temp fix to avoid computing overall swing\n",
    "df['pollupspredR'] = df['lagrepfr']+df['pollRfracdiff'] # temp fix to avoid computing overall swing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "3894d87d-6265-4bc3-afc1-b2bd436bbd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, year, fips, demfr, repfr, othfr, lagdemfr, lagrepfr, lagothfr, inc, mage, fage, edu, race, malefr, femalefr, pollDfracdiff, pollRfracdiff, pollupspredD, pollupspredR]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "rows_with_nan = df[df.isna().any(axis=1)]\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "cd27e978-d1a5-4421-bcfa-7396b34bc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add interaction term\n",
    "\n",
    "#df = df.dropna()\n",
    "df['male'] = df['malefr']*df['mage']\n",
    "df['female'] = df['femalefr']*df['fage']\n",
    "\n",
    "df_train = df[df['year']<2020]\n",
    "df_test = df[df['year']==2020]\n",
    "cols_to_drop1 = ['demfr','repfr','othfr','year','fips','lagothfr']\n",
    "cols_to_drop2 = ['inc','mage','fage','malefr','femalefr']\n",
    "#cols_to_drop3 = ['edu','race','male','female']\n",
    "X_train = df_train.drop(cols_to_drop1,axis=1)\n",
    "X_train = X_train.drop(cols_to_drop2,axis=1)\n",
    "X_train = X_train.drop(cols_to_drop3,axis=1)\n",
    "X_test = df_test.drop(cols_to_drop1,axis=1)\n",
    "X_test = X_test.drop(cols_to_drop2,axis=1)\n",
    "X_test = X_test.drop(cols_to_drop3,axis=1)\n",
    "y_train = df_train['demfr']\n",
    "y_test = df_test['demfr']\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "ca242b60-e397-45b0-a233-e5af510038ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15572, 22)\n",
      "(3115, 22)\n",
      "(12457, 22)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "641a6d4a-419a-4f9d-aa00-4866047cb9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.018673323123613753\n",
      "MSE: 0.000681962620979154\n"
     ]
    }
   ],
   "source": [
    "# now some basic machine learning\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "d9036ebe-0d9b-4744-a2d6-b48b8fa51f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20905627041318114, 0.0014742737408598994)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_err = y_pred - y_test\n",
    "max(abs(y_err)), min(abs(y_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "7752ee54-2d16-4d46-965d-83def3989a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.041494311233714457\n",
      "MSE: 0.003046660894738371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)  \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "fd1f89c1-0307-478f-8db4-5269792b0de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22429981240877972, 0.0003813271685854658)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_err = y_pred - y_test\n",
    "max(abs(y_err)), min(abs(y_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "a01d4911-0386-4d89-b4e2-645096e76264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.05332312348193685\n",
      "MSE: 0.004633693266638119\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=100, random_state=42) \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "5b879f7c-f63c-4e59-8d37-d53fae2dd2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23592253618303005, 9.684577951094009e-05)"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_err = y_pred - y_test\n",
    "max(abs(y_err)), min(abs(y_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "84a925db-24d9-4726-997e-6eb9809facd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Do not support special JSON characters in feature name.\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Do not support special JSON characters in feature name.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLightGBMError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[643]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[32m      2\u001b[39m model = LGBMRegressor(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)  \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model.fit(X_train, y_train)\n\u001b[32m      4\u001b[39m y_pred = model.predict(X_test)\n\u001b[32m      5\u001b[39m mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28msuper\u001b[39m().fit(\n\u001b[32m   1399\u001b[39m         X,\n\u001b[32m   1400\u001b[39m         y,\n\u001b[32m   1401\u001b[39m         sample_weight=sample_weight,\n\u001b[32m   1402\u001b[39m         init_score=init_score,\n\u001b[32m   1403\u001b[39m         eval_set=eval_set,\n\u001b[32m   1404\u001b[39m         eval_names=eval_names,\n\u001b[32m   1405\u001b[39m         eval_sample_weight=eval_sample_weight,\n\u001b[32m   1406\u001b[39m         eval_init_score=eval_init_score,\n\u001b[32m   1407\u001b[39m         eval_metric=eval_metric,\n\u001b[32m   1408\u001b[39m         feature_name=feature_name,\n\u001b[32m   1409\u001b[39m         categorical_feature=categorical_feature,\n\u001b[32m   1410\u001b[39m         callbacks=callbacks,\n\u001b[32m   1411\u001b[39m         init_model=init_model,\n\u001b[32m   1412\u001b[39m     )\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = train(\n\u001b[32m   1050\u001b[39m     params=params,\n\u001b[32m   1051\u001b[39m     train_set=train_set,\n\u001b[32m   1052\u001b[39m     num_boost_round=\u001b[38;5;28mself\u001b[39m.n_estimators,\n\u001b[32m   1053\u001b[39m     valid_sets=valid_sets,\n\u001b[32m   1054\u001b[39m     valid_names=eval_names,\n\u001b[32m   1055\u001b[39m     feval=eval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1056\u001b[39m     init_model=init_model,\n\u001b[32m   1057\u001b[39m     callbacks=callbacks,\n\u001b[32m   1058\u001b[39m )\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = Booster(params=params, train_set=train_set)\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/basic.py:3656\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3649\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_network(\n\u001b[32m   3650\u001b[39m         machines=machines,\n\u001b[32m   3651\u001b[39m         local_listen_port=params[\u001b[33m\"\u001b[39m\u001b[33mlocal_listen_port\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3652\u001b[39m         listen_time_out=params.get(\u001b[33m\"\u001b[39m\u001b[33mtime_out\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m120\u001b[39m),\n\u001b[32m   3653\u001b[39m         num_machines=params[\u001b[33m\"\u001b[39m\u001b[33mnum_machines\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3654\u001b[39m     )\n\u001b[32m   3655\u001b[39m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3656\u001b[39m train_set.construct()\n\u001b[32m   3657\u001b[39m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/basic.py:2590\u001b[39m, in \u001b[36mDataset.construct\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2585\u001b[39m             \u001b[38;5;28mself\u001b[39m._set_init_score_by_predictor(\n\u001b[32m   2586\u001b[39m                 predictor=\u001b[38;5;28mself\u001b[39m._predictor, data=\u001b[38;5;28mself\u001b[39m.data, used_indices=used_indices\n\u001b[32m   2587\u001b[39m             )\n\u001b[32m   2588\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2590\u001b[39m     \u001b[38;5;28mself\u001b[39m._lazy_init(\n\u001b[32m   2591\u001b[39m         data=\u001b[38;5;28mself\u001b[39m.data,\n\u001b[32m   2592\u001b[39m         label=\u001b[38;5;28mself\u001b[39m.label,\n\u001b[32m   2593\u001b[39m         reference=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2594\u001b[39m         weight=\u001b[38;5;28mself\u001b[39m.weight,\n\u001b[32m   2595\u001b[39m         group=\u001b[38;5;28mself\u001b[39m.group,\n\u001b[32m   2596\u001b[39m         init_score=\u001b[38;5;28mself\u001b[39m.init_score,\n\u001b[32m   2597\u001b[39m         predictor=\u001b[38;5;28mself\u001b[39m._predictor,\n\u001b[32m   2598\u001b[39m         feature_name=\u001b[38;5;28mself\u001b[39m.feature_name,\n\u001b[32m   2599\u001b[39m         categorical_feature=\u001b[38;5;28mself\u001b[39m.categorical_feature,\n\u001b[32m   2600\u001b[39m         params=\u001b[38;5;28mself\u001b[39m.params,\n\u001b[32m   2601\u001b[39m         position=\u001b[38;5;28mself\u001b[39m.position,\n\u001b[32m   2602\u001b[39m     )\n\u001b[32m   2603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.free_raw_data:\n\u001b[32m   2604\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/basic.py:2227\u001b[39m, in \u001b[36mDataset._lazy_init\u001b[39m\u001b[34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[39m\n\u001b[32m   2225\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWrong predictor type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(predictor).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   2226\u001b[39m \u001b[38;5;66;03m# set feature names\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2227\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.set_feature_name(feature_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/basic.py:3046\u001b[39m, in \u001b[36mDataset.set_feature_name\u001b[39m\u001b[34m(self, feature_name)\u001b[39m\n\u001b[32m   3042\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3043\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLength of feature_name(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feature_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) and num_feature(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_feature()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3044\u001b[39m         )\n\u001b[32m   3045\u001b[39m     c_feature_name = [_c_str(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m feature_name]\n\u001b[32m-> \u001b[39m\u001b[32m3046\u001b[39m     _safe_call(\n\u001b[32m   3047\u001b[39m         _LIB.LGBM_DatasetSetFeatureNames(\n\u001b[32m   3048\u001b[39m             \u001b[38;5;28mself\u001b[39m._handle,\n\u001b[32m   3049\u001b[39m             _c_array(ctypes.c_char_p, c_feature_name),\n\u001b[32m   3050\u001b[39m             ctypes.c_int(\u001b[38;5;28mlen\u001b[39m(feature_name)),\n\u001b[32m   3051\u001b[39m         )\n\u001b[32m   3052\u001b[39m     )\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/basic.py:313\u001b[39m, in \u001b[36m_safe_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    The return value from C API calls.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB.LGBM_GetLastError().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mLightGBMError\u001b[39m: Do not support special JSON characters in feature name."
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model = LGBMRegressor(n_estimators=100, random_state=42)  \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "e536a330-a803-441f-a16d-4f32250df999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23592253618303005, 9.684577951094009e-05)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_err = y_pred - y_test\n",
    "max(abs(y_err)), min(abs(y_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "7e8dbf1e-38e2-42c1-ad7d-dd6ff64b1ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.035171254143620274\n",
      "MSE: 0.0016986463176102296\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.Ridge(alpha=0.7)  \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "15291f8f-10c3-468c-8393-1df4e4bae19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20922616596423188, 0.0009982371027911774)"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_err = y_pred - y_test\n",
    "max(abs(y_err)), min(abs(y_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "3b73a67a-4507-460f-9b59-47a9e851f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.14014924501009496\n",
      "MSE: 0.03671151792519278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=5)  \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_true=y_test,y_pred=y_pred)\n",
    "mse = mean_squared_error(y_true=y_test,y_pred=y_pred) #default=True\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "5e3634a4-65e6-42ed-935c-66b991e52100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6946871771424405, 0.00015290691013999935)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_err = y_pred - y_test\n",
    "max(abs(y_err)), min(abs(y_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "7f9a2b8c-6e85-4638-8714-39e932e962ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b91dc9-5bbc-482c-9145-0cae507c5d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
